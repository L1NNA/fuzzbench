version: "3"
services:
  llm_fuzz:
    depends_on:
      redis_service:
        condition: service_healthy
    build:
      context: .
      dockerfile: llm.Dockerfile
    tty: true
    network_mode: host
  redis_service:
    image: redis:latest
    command: >
      --requirepass password
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli --pass password ping | grep PONG" ]
      interval: 1s
      timeout: 3s
      retries: 5
    network_mode: host
  llm_service:
    image: ollama/ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    network_mode: host